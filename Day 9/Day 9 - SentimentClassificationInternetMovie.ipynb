{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f591bde2-868e-4daf-9cd6-49aa83c7fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f6c61ee-3887-4eb1-b7f3-b11554b1964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sande\\anaconda3\\envs\\local\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59d9771-9a86-464c-8b12-5c3b4b0a9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44cad18-1e48-4026-93b3-f8b0260f0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and Dependencies\n",
    "from fastbook import *\n",
    "from fastai.text.all import *\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3c217d-af18-4219-b27b-151aa6a51398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastai has a number of Dataset which makes easy to download and to use. Let's use IMDB Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663579b0-a48f-4bb7-9199-5b347ec7641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and accessing the IMDB Dataset\n",
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d253fb50-bf01-44ae-8a4c-f73202624369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_text_files function is used to grab all the text files in a path obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d77b28-685d-462f-a155-479ba9b572ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrifi'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting all the text Files\n",
    "files = get_text_files(path, folders=[\"train\",\"test\",\"unsup\"])\n",
    "\n",
    "# Inspecting the files\n",
    "text = files[0].open().read()\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69ea6b-f26d-4fce-ac01-d184c9404b82",
   "metadata": {},
   "source": [
    "Word Tokenization:\n",
    "    I have used Fastai Tokenizer for the process of Word Tokenization. Then, I will use Fastai coll_repr function to display the results. It displays the first n items of the collection. The collection of text documents should be wrap into list. The tokens starting with xx are the special tokens which is not a common word prefix in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b766372c-8fed-4844-b14d-18fb117d0ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#207) ['xxbos','xxmaj','once','again','xxmaj','mr','.','xxmaj','costner','has','dragged','out','a','movie','for','far','longer','than','necessary','.','xxmaj','aside','from','the','terrific','sea','rescue','sequences',',','of'...]\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Word tokenization\n",
    "spacy = WordTokenizer()\n",
    "\n",
    "tokens = Tokenizer(spacy)\n",
    "display(coll_repr(tokens(text), 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a903627-55e3-41b4-97d9-0f2f0ba08185",
   "metadata": {},
   "source": [
    "Subword Tokenization:\n",
    "In Chinese and Japanese languages there are no spaces in the sentences. Similarly Turkish languages add many subwords together without spaces creating very long words. In such problems the Subword tokenization plays the key role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74608565-ab25-4c2f-8634-dca3cdd5e027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'▁O n ce ▁again ▁M r . ▁Co st n er ▁has ▁ d ra g g ed ▁out ▁a ▁movie ▁for ▁far ▁long er ▁than ▁ ne ce s s ar y . ▁A side ▁from ▁the ▁ ter'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subword Tokenization\n",
    "texts = L(x.open().read() for x in files[:2000])\n",
    "\n",
    "def subword(sz):\n",
    "    sp = SubwordTokenizer(vocab_sz=sz)\n",
    "    sp.setup(texts)\n",
    "    return \" \".join(first(sp([text]))[:40])\n",
    "\n",
    "subword(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee08673-6412-4446-8d75-104629470121",
   "metadata": {},
   "source": [
    "Numericalization:\n",
    "Numericalization is the process of mapping tokens to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd6ada01-05f7-40da-998b-77e4aedce4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#207) ['xxbos','xxmaj','once','again','xxmaj','mr','.','xxmaj','costner','has'...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#1968) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the','.',',','a','and','of','to','is','it','i','in','this','\"','that','-',\"'s\",'movie','\\n\\n','was','for','but'...]\n"
     ]
    }
   ],
   "source": [
    "# Numericalization\n",
    "token = tokens(text)\n",
    "token200 = texts[:200].map(tokens)\n",
    "# tokens200 = text[:200].map(lambda x: tokens(x).cpu())\n",
    "display(token200[0])\n",
    "\n",
    "num = Numericalize()\n",
    "num.setup(token200)\n",
    "print(coll_repr(num.vocab, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d21e474-a9b1-48af-9a81-deb485497036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shape of X is torch.Size([64, 72])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shape of y is torch.Size([64, 72])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing LMDataLoader\n",
    "nums200 = token200.map(num)\n",
    "dl = LMDataLoader(nums200)\n",
    "\n",
    "# Inspecting the LMDataLoader\n",
    "X, y = first(dl)\n",
    "display(f\"Shape of X is {X.shape}\")\n",
    "display(f\"Shape of y is {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b585e-9df7-4cf5-8b72-1d9166fd424e",
   "metadata": {},
   "source": [
    "### Training the Text Classifier\n",
    "Assembling the Data for training. There are two steps for training the state of art Text classifier using Transfer Learning. First the model should be fine tuned on IMDB reviews corpus on Wikipedia. Then the model can be used to train the classifier.\n",
    "#### Language Model using DataBlock\n",
    "Fastai handles Tokenization and Numericalization automatically when TextBlock is passed to the DataBlock. All the arguments that can be passed to Tokenize and Numericalize can also be passed to the TetxBlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c9457b9-e7a1-4aff-8e5c-33a2d162f8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj this is one strange movie , from floating images of xxmaj greek statues to flashy images in a</td>\n",
       "      <td>xxmaj this is one strange movie , from floating images of xxmaj greek statues to flashy images in a picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whose inane , excruciating , nails - on - blackboard screeching is enough to make one wish that xxmaj freddie</td>\n",
       "      <td>inane , excruciating , nails - on - blackboard screeching is enough to make one wish that xxmaj freddie xxmaj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing the Language Model using DataBlock.\n",
    "get_imdb = partial(get_text_files, folders=[\"train\", \"test\", \"unsup\"])\n",
    "\n",
    "# Preparing DataBlock.\n",
    "dls_lm = DataBlock(\n",
    "    blocks = TextBlock.from_folder(path, is_lm=True),\n",
    "    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
    ").dataloaders(path, path=path, bs=32, seq_len=20)\n",
    "\n",
    "# Inspecting the DataBlock.\n",
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68158921",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "306ad96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Language Model\n",
    "learn = language_model_learner(\n",
    "    dls_lm, AWD_LSTM, drop_mult=0.3,\n",
    "    metrics = [accuracy, Perplexity()]\n",
    ").to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = learn.model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a202bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = learn.model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "948ddabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='10227' class='' max='42066' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      24.31% [10227/42066 1:32:26&lt;4:47:47 4.7751]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training the model\n",
    "learn.fit_one_cycle(1, 2e-2)                    # Training the Model for one Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c664ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
